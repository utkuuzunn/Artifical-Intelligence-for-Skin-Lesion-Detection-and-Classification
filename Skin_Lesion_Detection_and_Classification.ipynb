{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4FrJ_IVEWCV"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Kaggle'dan projede kullanılacak olan datasetin indirilmesi ve dosya yolunun kaydedilmesi\n",
        "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    import os\n",
        "    import shutil\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.utils import resample\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    import numpy as np\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    import tensorflow as tf\n",
        "\n",
        "    image_path1 = '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_images_part_1'\n",
        "    image_path2 = '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_images_part_2'\n",
        "\n",
        "    final_image_dataset = '/kaggle/working/skin-cancer-mnist-ham10000_combined'\n",
        "\n",
        "    os.makedirs(final_image_dataset, exist_ok=True)\n",
        "\n",
        "    def copy_images(source_path, destination_path):\n",
        "        for filename in os.listdir(source_path):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                shutil.copy(os.path.join(source_path, filename), destination_path)\n",
        "\n",
        "    copy_images(image_path1, final_image_dataset)\n",
        "    copy_images(image_path2, final_image_dataset)\n",
        "\n",
        "    metadata_path = '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_metadata.csv'\n",
        "    meta_data = pd.read_csv(metadata_path)\n",
        "\n",
        "    meta_data['Image_path'] = meta_data['image_id'].apply(lambda x: os.path.join(final_image_dataset, f\"{x}.jpg\"))\n",
        "\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    meta_data['label'] = le.fit_transform(meta_data[\"dx\"])\n",
        "    meta_data['label'] = meta_data['label'].astype(str)\n",
        "\n",
        "\n",
        "    n_samples = 5000\n",
        "\n",
        "    df_nv = meta_data[meta_data['dx'] == 'nv']\n",
        "    df_mel = meta_data[meta_data['dx'] == 'mel']\n",
        "    df_bkl = meta_data[meta_data['dx'] == 'bkl']\n",
        "    df_bcc = meta_data[meta_data['dx'] == 'bcc']\n",
        "    df_akiec = meta_data[meta_data['dx'] == 'akiec']\n",
        "    df_vasc = meta_data[meta_data['dx'] == 'vasc']\n",
        "    df_df = meta_data[meta_data['dx'] == 'df']\n",
        "\n",
        "    df_nv_balanced = resample(df_nv, replace=False, n_samples=n_samples, random_state=42)\n",
        "    df_mel_balanced = resample(df_mel, replace=True, n_samples=n_samples, random_state=42)\n",
        "    df_bkl_balanced = resample(df_bkl, replace=True, n_samples=n_samples, random_state=42)\n",
        "    df_bcc_balanced = resample(df_bcc, replace=True, n_samples=n_samples, random_state=42)\n",
        "    df_akiec_balanced = resample(df_akiec, replace=True, n_samples=n_samples, random_state=42)\n",
        "    df_vasc_balanced = resample(df_vasc, replace=True, n_samples=n_samples, random_state=42)\n",
        "    df_df_balanced = resample(df_df, replace=True, n_samples=n_samples, random_state=42)\n",
        "\n",
        "    balanced_meta_data = pd.concat([df_nv_balanced, df_mel_balanced, df_bkl_balanced,\n",
        "                                    df_bcc_balanced, df_akiec_balanced, df_vasc_balanced,\n",
        "                                    df_df_balanced])\n",
        "    label_mapping = {\n",
        "        'nv': 'Melanocytic Nevus',\n",
        "        'mel': 'Melanoma',\n",
        "        'bkl': 'Benign Keratosis',\n",
        "        'bcc': 'Basal Cell Carcinoma',\n",
        "        'akiec': 'Actinic Keratosis',\n",
        "        'vasc': 'Vascular Lesion',\n",
        "        'df': 'Dermatofibroma'\n",
        "    }\n",
        "\n",
        "    balanced_meta_data['dx'] = balanced_meta_data['dx'].replace(label_mapping)\n",
        "\n",
        "    print(balanced_meta_data['dx'].value_counts())\n",
        "\n",
        "    balanced_meta_data = balanced_meta_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(f\"Balanced dataset class distribution:\\n{balanced_meta_data['dx'].value_counts()}\")\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    train_meta, test_meta = train_test_split(balanced_meta_data, test_size=0.3, random_state=42)\n",
        "    train_meta, val_meta = train_test_split(train_meta, test_size=0.3, random_state=42)\n",
        "\n",
        "    print(f\"Training set size: {len(train_meta)}\")\n",
        "    print(f\"Validation set size: {len(val_meta)}\")\n",
        "    print(f\"Testing set size: {len(test_meta)}\")\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_meta,\n",
        "        directory=final_image_dataset,\n",
        "        x_col='Image_path',\n",
        "        y_col='label',\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=val_meta,\n",
        "        directory=final_image_dataset,\n",
        "        x_col='Image_path',\n",
        "        y_col='label',\n",
        "        target_size=(128,128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_meta,\n",
        "        directory=final_image_dataset,\n",
        "        x_col='Image_path',\n",
        "        y_col='label',\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n"
      ],
      "metadata": {
        "id": "CuvhEepIEtN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Sınıf sayısı yani datasette tanımlı etiket (lezyon türü) sayısı\n",
        "num_classes = 7\n",
        "\n",
        "# Modeli tanımlama\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(128, 128, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6ZaLuFOBEtME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Girilen epoch sayısına göre modelin dataseti kaç kez işleneceğini belirlenir\n",
        "# History nesnesiyle modelin performansı analiz edilmek için her bir epoch sonrası kaydedilir\n",
        "# Val_generator her bir epoch sonunda modelin performansını gerçek veriler ile karşılaştırarak ölçer\n",
        "history = model.fit(validation_data=val_generator,epochs=10)"
      ],
      "metadata": {
        "id": "w4I8-KUzEtJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Genel olarak bir önceki aşamada ki modelin performans verilerini kullanarak modelin doğruluk değerini bulur\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "QnCLFNs4EtHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Etiketlerin (lezyon türü) gerçek isimleri ve etiket numaraları\n",
        "class_labels = {\n",
        "    0: 'Actinic Keratosis',    # akiec\n",
        "    1: 'Basal Cell Carcinoma', # bcc\n",
        "    2: 'Benign Keratosis',     # bkl\n",
        "    3: 'Dermatofibroma',       # df\n",
        "    4: 'Melanoma',            # mel\n",
        "    5: 'Melanocytic Nevi',    # nv\n",
        "    6: 'Vascular Lesion'      # vasc\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels.values()))\n",
        "\n",
        "# Modelin genel olarak doğruluğunu, hassasiyetini, duyarlılığını ve f1 puanını hesaplar ve yazdırır\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
        "\n",
        "# Modelin eğitimi boyunca elde edilen model parametrelerini tablo halinde her bir epoch sonunda olacak şekilde yazdırır\n",
        "def plot_metrics(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Eğitim sürecindeki elde edilen model parametrelerini grafik olarak gösterir\n",
        "plot_metrics(history)"
      ],
      "metadata": {
        "id": "Og2RJPWWEtFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Modeli kullanarak belirtilen görüntü dosyalarını sınıflandırarak ve tahmin edilen sonuçları\n",
        "# datasetteki gerçek etiketler ile birlikte bir grafik üzerinde görselleştirir ve gerçek etiket değeri ile\n",
        "# modelin tahmini arasındaki farkı görmemizi sağlar.\n",
        "def classify_and_plot_images(model, image_paths, true_labels):\n",
        "    plt.figure(figsize=(30, 15))\n",
        "\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        img = load_img(image_path, target_size=(128,128))\n",
        "        img_array = img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = img_array / 255.0\n",
        "\n",
        "        prediction = model.predict(img_array)\n",
        "        predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "        confidence = np.max(prediction)\n",
        "\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(load_img(image_path))\n",
        "        plt.title(f\"True: {class_labels[true_labels[i]]}\\nPredicted: {class_labels[predicted_class]}\\nAccuracy: {confidence:.2f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Etiketlemiş olduğumuz veri setinden rastgele 8 örnek seçer\n",
        "sample_metadata = meta_data.sample(n=8)\n",
        "\n",
        "# Seçilen görüntülerin dosya adı (.jpg ve .png şeklinde) ve dosya yolu oluşturularak boş bir liste oluşturulur ve buraya kaydedilir\n",
        "sample_image_paths = []\n",
        "sample_true_labels = []\n",
        "for _, row in sample_metadata.iterrows():\n",
        "    image_id = row['image_id'] + '.jpg'\n",
        "    image_path = os.path.join(final_image_dataset, image_id)\n",
        "    # Görüntülerin dosya yollarını kontrol ederek doğru dosya yolunda bulunma kontorlü yapar\n",
        "    if os.path.exists(image_path):\n",
        "        sample_image_paths.append(image_path)\n",
        "        sample_true_labels.append(label_mapping[row['dx']])\n",
        "    else:\n",
        "        print(f\"Warning: Image {image_path} not found.\")\n",
        "\n",
        "# Oluşturulan listeleri kontrol eder ve yapılan lezyon türü sınıflandırmasına göre seçilen görüntülerle oluşturulan listeleri çağrırır\n",
        "print(\"Sample image paths:\", sample_image_paths)\n",
        "print(\"Sample true labels:\", sample_true_labels)\n",
        "\n",
        "# Seçilen görüntüler için mevcut olan lezyon türü etiketleri\n",
        "class_labels = {\n",
        "    0: 'Actinic Keratosis',\n",
        "    1: 'Basal Cell Carcinoma',\n",
        "    2: 'Benign Keratosis',\n",
        "    3: 'Dermatofibroma',\n",
        "    4: 'Melanoma',\n",
        "    5: 'Melanocytic Nevi',\n",
        "    6: 'Vascular Lesion'\n",
        "}\n",
        "\n",
        "if sample_image_paths and sample_true_labels:\n",
        "    classify_and_plot_images(model, sample_image_paths, sample_true_labels)\n",
        "else:\n",
        "    print(\"No valid images found. Please check the image paths.\")"
      ],
      "metadata": {
        "id": "TdkaECCfEtDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}